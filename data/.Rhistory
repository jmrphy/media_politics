Sys.setlocale(locale="C")
per1<-df[1:27392,]
per2<-df[27393:54785,]
per3<-df[54786:82177,]
per4<-df[82178:109569,]
per5<-df[109569:136960,]
# Let's Identify retweets
# regular expressions to find retweets
grep("(RT|via)((?:\\b\\W*@\\w+)+)", df$text,
ignore.case=TRUE, value=TRUE)
##### Network Snapshot 1
# which tweets are retweets
rt_patterns = grep("(RT|via)((?:\\b\\W*@\\w+)+)",
per1$text, ignore.case=TRUE)
# Collect who retweeted and who posted
# We'll use these results to form an edge list in order to create the graph
# create list to store user names
who_retweet = as.list(1:length(rt_patterns))
who_post = as.list(1:length(rt_patterns))
# for loop
for (i in 1:length(rt_patterns))
{
# get tweet with retweet entity
twit = per1[rt_patterns[i],]
# get retweet source
poster = str_extract_all(twit$text,
"(RT|via)((?:\\b\\W*@\\w+)+)")
#remove ':'
poster = gsub(":", "", unlist(poster))
# name of retweeted user
who_post[[i]] = gsub("(RT @|via @)", "", poster, ignore.case=TRUE)
# name of retweeting user
who_retweet[[i]] = rep(twit$user.screen_name, length(poster))
}
# unlist results
who_post = unlist(who_post)
who_retweet = unlist(who_retweet)
# print(paste(length(unique(who_post)), " users retweeted by ", length(unique(who_retweet)), " users ", sep=""))
# Create graph from an edglist
# two column matrix of edges
retweeter_poster = cbind(who_retweet, who_post)
# generate graph
el.df1<-as.data.frame(retweeter_poster)
el.df1<-el.df1[order(el.df1$who_post),]
el.df1<-el.df1[-grep(" ", el.df1$who_post),]  # remove RTs of multiples
rownames(el.df1)<-NULL
write.csv(el.df1, "cleaned_data/migration_el1.csv")
##### Network Snapshot 2
# which tweets are retweets
rt_patterns = grep("(RT|via)((?:\\b\\W*@\\w+)+)",
per2$text, ignore.case=TRUE)
# Collect who retweeted and who posted
# We'll use these results to form an edge list in order to create the graph
# create list to store user names
who_retweet = as.list(1:length(rt_patterns))
who_post = as.list(1:length(rt_patterns))
# for loop
for (i in 1:length(rt_patterns))
{
# get tweet with retweet entity
twit = per2[rt_patterns[i],]
# get retweet source
poster = str_extract_all(twit$text,
"(RT|via)((?:\\b\\W*@\\w+)+)")
#remove ':'
poster = gsub(":", "", unlist(poster))
# name of retweeted user
who_post[[i]] = gsub("(RT @|via @)", "", poster, ignore.case=TRUE)
# name of retweeting user
who_retweet[[i]] = rep(twit$user.screen_name, length(poster))
}
# unlist results
who_post = unlist(who_post)
who_retweet = unlist(who_retweet)
# print(paste(length(unique(who_post)), " users retweeted by ", length(unique(who_retweet)), " users ", sep=""))
# Create graph from an edglist
# two column matrix of edges
retweeter_poster = cbind(who_retweet, who_post)
# generate graph
el.df2<-as.data.frame(retweeter_poster)
el.df2<-el.df2[order(el.df2$who_post),]
el.df2<-el.df2[-grep(" ", el.df2$who_post),]  # remove RTs of multiples
rownames(el.df2)<-NULL
write.csv(el.df2, "cleaned_data/migration_el2.csv")
##### Network Snapshot 3
# which tweets are retweets
rt_patterns = grep("(RT|via)((?:\\b\\W*@\\w+)+)",
per3$text, ignore.case=TRUE)
# Collect who retweeted and who posted
# We'll use these results to form an edge list in order to create the graph
# create list to store user names
who_retweet = as.list(1:length(rt_patterns))
who_post = as.list(1:length(rt_patterns))
# for loop
for (i in 1:length(rt_patterns))
{
# get tweet with retweet entity
twit = per3[rt_patterns[i],]
# get retweet source
poster = str_extract_all(twit$text,
"(RT|via)((?:\\b\\W*@\\w+)+)")
#remove ':'
poster = gsub(":", "", unlist(poster))
# name of retweeted user
who_post[[i]] = gsub("(RT @|via @)", "", poster, ignore.case=TRUE)
# name of retweeting user
who_retweet[[i]] = rep(twit$user.screen_name, length(poster))
}
# unlist results
who_post = unlist(who_post)
who_retweet = unlist(who_retweet)
# print(paste(length(unique(who_post)), " users retweeted by ", length(unique(who_retweet)), " users ", sep=""))
# Create graph from an edglist
# two column matrix of edges
retweeter_poster = cbind(who_retweet, who_post)
# generate graph
el.df3<-as.data.frame(retweeter_poster)
el.df3<-el.df3[order(el.df3$who_post),]
el.df3<-el.df3[-grep(" ", el.df3$who_post),]  # remove RTs of multiples
rownames(el.df3)<-NULL
write.csv(el.df3, "cleaned_data/migration_el3.csv")
##### Network Snapshot 4
# which tweets are retweets
rt_patterns = grep("(RT|via)((?:\\b\\W*@\\w+)+)",
per4$text, ignore.case=TRUE)
# Collect who retweeted and who posted
# We'll use these results to form an edge list in order to create the graph
# create list to store user names
who_retweet = as.list(1:length(rt_patterns))
who_post = as.list(1:length(rt_patterns))
# for loop
for (i in 1:length(rt_patterns))
{
# get tweet with retweet entity
twit = per4[rt_patterns[i],]
# get retweet source
poster = str_extract_all(twit$text,
"(RT|via)((?:\\b\\W*@\\w+)+)")
#remove ':'
poster = gsub(":", "", unlist(poster))
# name of retweeted user
who_post[[i]] = gsub("(RT @|via @)", "", poster, ignore.case=TRUE)
# name of retweeting user
who_retweet[[i]] = rep(twit$user.screen_name, length(poster))
}
# unlist results
who_post = unlist(who_post)
who_retweet = unlist(who_retweet)
# print(paste(length(unique(who_post)), " users retweeted by ", length(unique(who_retweet)), " users ", sep=""))
# Create graph from an edglist
# two column matrix of edges
retweeter_poster = cbind(who_retweet, who_post)
# generate graph
el.df4<-as.data.frame(retweeter_poster)
el.df4<-el.df4[order(el.df4$who_post),]
el.df4<-el.df4[-grep(" ", el.df4$who_post),]  # remove RTs of multiples
rownames(el.df4)<-NULL
write.csv(el.df4, "cleaned_data/migration_el4.csv")
##### Network Snapshot 5
# which tweets are retweets
rt_patterns = grep("(RT|via)((?:\\b\\W*@\\w+)+)",
per5$text, ignore.case=TRUE)
# Collect who retweeted and who posted
# We'll use these results to form an edge list in order to create the graph
# create list to store user names
who_retweet = as.list(1:length(rt_patterns))
who_post = as.list(1:length(rt_patterns))
# for loop
for (i in 1:length(rt_patterns))
{
# get tweet with retweet entity
twit = per5[rt_patterns[i],]
# get retweet source
poster = str_extract_all(twit$text,
"(RT|via)((?:\\b\\W*@\\w+)+)")
#remove ':'
poster = gsub(":", "", unlist(poster))
# name of retweeted user
who_post[[i]] = gsub("(RT @|via @)", "", poster, ignore.case=TRUE)
# name of retweeting user
who_retweet[[i]] = rep(twit$user.screen_name, length(poster))
}
# unlist results
who_post = unlist(who_post)
who_retweet = unlist(who_retweet)
# print(paste(length(unique(who_post)), " users retweeted by ", length(unique(who_retweet)), " users ", sep=""))
# Create graph from an edglist
# two column matrix of edges
retweeter_poster = cbind(who_retweet, who_post)
# generate graph
el.df5<-as.data.frame(retweeter_poster)
el.df5<-el.df5[order(el.df5$who_post),]
el.df5<-el.df5[-grep(" ", el.df5$who_post),]  # remove RTs of multiples
rownames(el.df5)<-NULL
write.csv(el.df5, "cleaned_data/migration_el5.csv")
setwd("~/Dropbox/gh_projects/migration_tweets/cleaned_data")
el.df1<-read.csv("migration_el1.csv") # read in edgelist
el.df2<-read.csv("migration_el2.csv") # read in edgelist
el.df3<-read.csv("migration_el3.csv") # read in edgelist
el.df4<-read.csv("migration_el4.csv") # read in edgelist
el.df5<-read.csv("migration_el5.csv") # read in edgelist
setwd("~/Dropbox/gh_projects/migration_tweets")
el.df1<-el.df1[,2:3]
el.df2<-el.df2[,2:3]
el.df3<-el.df3[,2:3]
el.df4<-el.df4[,2:3]
el.df5<-el.df5[,2:3]
rt_graph2.1 = graph.edgelist(as.matrix(el.df1), directed=TRUE)
rt_graph2.2 = graph.edgelist(as.matrix(el.df2), directed=TRUE)
rt_graph2.3 = graph.edgelist(as.matrix(el.df3), directed=TRUE)
rt_graph2.4 = graph.edgelist(as.matrix(el.df4), directed=TRUE)
rt_graph2.5 = graph.edgelist(as.matrix(el.df5), directed=TRUE)
# Make and plot graph
rt_graph2.1 = delete.vertices(rt_graph2.1, V(rt_graph2.1)[ degree(rt_graph2.1)<=1 ])
rt_graph2.2 = delete.vertices(rt_graph2.2, V(rt_graph2.2)[ degree(rt_graph2.2)<=1 ])
rt_graph2.3 = delete.vertices(rt_graph2.3, V(rt_graph2.3)[ degree(rt_graph2.3)<=1 ])
rt_graph2.4 = delete.vertices(rt_graph2.4, V(rt_graph2.4)[ degree(rt_graph2.4)<=1 ])
rt_graph2.5 = delete.vertices(rt_graph2.5, V(rt_graph2.5)[ degree(rt_graph2.5)<=1 ])
V(rt_graph2.1)$color[betweenness(rt_graph2.1)>1000] =  rgb(1,0,0,1)
V(rt_graph2.2)$color[betweenness(rt_graph2.2)>1000] =  rgb(1,0,0,1)
V(rt_graph2.3)$color[betweenness(rt_graph2.3)>1000] =  rgb(1,0,0,1)
V(rt_graph2.4)$color[betweenness(rt_graph2.4)>1000] =  rgb(1,0,0,1)
V(rt_graph2.5)$color[betweenness(rt_graph2.5)>1000] =  rgb(1,0,0,1)
V(rt_graph2.1)$color[evcent(rt_graph2.1)$vector>.3] =  rgb(0,1,0,1)
V(rt_graph2.2)$color[evcent(rt_graph2.2)$vector>.3] =  rgb(0,1,0,1)
V(rt_graph2.3)$color[evcent(rt_graph2.3)$vector>.3] =  rgb(0,1,0,1)
V(rt_graph2.4)$color[evcent(rt_graph2.4)$vector>.3] =  rgb(0,1,0,1)
V(rt_graph2.5)$color[evcent(rt_graph2.5)$vector>.3] =  rgb(0,1,0,1)
V(rt_graph2.1)$size = 2
V(rt_graph2.2)$size = 2
V(rt_graph2.3)$size = 2
V(rt_graph2.4)$size = 2
V(rt_graph2.5)$size = 2
V(rt_graph2.1)$label[evcent(rt_graph2.1)$vector>.3] = V(rt_graph2.1)$name[evcent(rt_graph2.1)$vector>.3]
V(rt_graph2.2)$label[evcent(rt_graph2.2)$vector>.3] = V(rt_graph2.2)$name[evcent(rt_graph2.2)$vector>.3]
V(rt_graph2.3)$label[evcent(rt_graph2.3)$vector>.3] = V(rt_graph2.3)$name[evcent(rt_graph2.3)$vector>.3]
V(rt_graph2.4)$label[evcent(rt_graph2.4)$vector>.3] = V(rt_graph2.4)$name[evcent(rt_graph2.4)$vector>.3]
V(rt_graph2.5)$label[evcent(rt_graph2.5)$vector>.3] = V(rt_graph2.5)$name[evcent(rt_graph2.5)$vector>.3]
V(rt_graph2.1)$label[betweenness(rt_graph2.1)>1000] = V(rt_graph2.1)$name[betweenness(rt_graph2.1)>1000]
V(rt_graph2.2)$label[betweenness(rt_graph2.2)>1000] = V(rt_graph2.2)$name[betweenness(rt_graph2.2)>1000]
V(rt_graph2.3)$label[betweenness(rt_graph2.3)>1000] = V(rt_graph2.3)$name[betweenness(rt_graph2.3)>1000]
V(rt_graph2.4)$label[betweenness(rt_graph2.4)>1000] = V(rt_graph2.4)$name[betweenness(rt_graph2.4)>1000]
V(rt_graph2.5)$label[betweenness(rt_graph2.5)>1000] = V(rt_graph2.5)$name[betweenness(rt_graph2.5)>1000]
V(rt_graph2.1)$label.cex = 1.2
V(rt_graph2.2)$label.cex = 1.2
V(rt_graph2.3)$label.cex = 1.2
V(rt_graph2.4)$label.cex = 1.2
V(rt_graph2.5)$label.cex = 1.2
E(rt_graph2.1)$width = .3
E(rt_graph2.2)$width = .3
E(rt_graph2.3)$width = .3
E(rt_graph2.4)$width = .3
E(rt_graph2.5)$width = .3
E(rt_graph2.1)$color = rgb(.5,.5,0,.1)
E(rt_graph2.2)$color = rgb(.5,.5,0,.1)
E(rt_graph2.3)$color = rgb(.5,.5,0,.1)
E(rt_graph2.4)$color = rgb(.5,.5,0,.1)
E(rt_graph2.5)$color = rgb(.5,.5,0,.1)
set.seed(4074)
par(bg="white", mar=c(1,1,1,1), mfrow=c(2,3))
plot.igraph(rt_graph2.1, layout=layout.fruchterman.reingold, vertex.label.color= "white", main="Snapshot 1")
plot.igraph(rt_graph2.2, layout=layout.fruchterman.reingold, vertex.label.color= "white", main="Snapshot 2")
plot.igraph(rt_graph2.3, layout=layout.fruchterman.reingold, vertex.label.color= "white", main="Snapshot 3")
plot.igraph(rt_graph2.4, layout=layout.fruchterman.reingold, vertex.label.color= "white", main="Snapshot 4")
plot.igraph(rt_graph2.5, layout=layout.fruchterman.reingold, vertex.label.color= "white", main="Snapshot 5")
set.seed(4074)
par(bg="white", mar=c(1,1,1,1), mfrow=c(2,3))
plot.igraph(rt_graph2.1, layout=layout.fruchterman.reingold, vertex.label.color= "red", main="Snapshot 1")
plot.igraph(rt_graph2.2, layout=layout.fruchterman.reingold, vertex.label.color= "red", main="Snapshot 2")
plot.igraph(rt_graph2.3, layout=layout.fruchterman.reingold, vertex.label.color= "red", main="Snapshot 3")
plot.igraph(rt_graph2.4, layout=layout.fruchterman.reingold, vertex.label.color= "red", main="Snapshot 4")
plot.igraph(rt_graph2.5, layout=layout.fruchterman.reingold, vertex.label.color= "red", main="Snapshot 5")
df$cleantext<-gsub('http.* *', ' ', df$text)
df$cleantext<-str_replace_all(df$cleantext, "[^[:alnum:]]", " ")
corp<-Corpus(VectorSource(df$cleantext))
corp <- tm_map(corp, removeNumbers)
corp <- tm_map(corp, removePunctuation)
corp <- tm_map(corp, stripWhitespace)
my_stopwords <- c(stopwords('english'), paste(unique(df$screenName)))
corp <- tm_map(corp, removeWords, my_stopwords)
corp <- tm_map(corp, tolower)
corp.full<-corp
corp <- tm_map(corp, stemDocument, language = "english") #reduce all English words to their roots
# other_stop_words<-c("psa", "polit", "rt", "panel", "amp", "politicalspik", "angeliawilson",
#                     "politicsir", "peterjohn", "the")
# corp <- tm_map(corp, removeWords, other_stop_words)   # remove specific word (the hashtag of interest)
dtm <-DocumentTermMatrix(corp) # make a matrix of each document by every single term
dtm <- removeSparseTerms(dtm, 0.99)
terms<-as.data.frame(sort(colSums(inspect(dtm)), decreasing=TRUE))
terms$Term <- rownames(terms)
names(terms)<-c("Frequency", "Term")
rownames(terms) = NULL
terms[1:50,1:2]
?inspect
terms<-as.data.frame(sort(colSums(dtm), decreasing=TRUE))
terms<-as.data.frame(sort(colSums(summary(dtm)), decreasing=TRUE))
dtm
terms<-as.data.frame(sort(colSums(table(dtm)), decreasing=TRUE))
terms<-as.data.frame(sort(colSums(dtm), decreasing=TRUE))
terms<-as.data.frame(sort(colSums(inspect(dtm)), decreasing=TRUE))
terms$Term <- rownames(terms)
names(terms)<-c("Frequency", "Term")
rownames(terms) = NULL
terms[1:50,1:2]
setwd("~/Dropbox/gh_projects/migration_tweets/preliminary")
hu.liu.pos=scan("positive-words.txt",what='character',comment.char=';') #load +ve sentiment word list
hu.liu.neg=scan("negative-words.txt",what='character',comment.char=';') #load -ve sentiment word list
pos.words=c(hu.liu.pos)
neg.words=c(hu.liu.neg)
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an "l" for us
# we want a simple array ("a") of scores back, so we use
# "l" + "a" + "ply" = "laply":
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R's regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
corp.full<-unlist(corp.full)
corp.scores<-score.sentiment(corp.full,pos.words,neg.words,.progress='text') # get scores for the tweet text
ggplot(corp.scores, aes(x=score)) + geom_histogram(binwidth=1) + xlab("Sentiment score") + ylab("Frequency") + theme_bw() + ggtitle("The Distribution of Sentiment")
corp.pos<-subset(corp.scores,corp.scores$score>=4) # get tweets with only very +ve scores
corp.neg<-subset(corp.scores,corp.scores$score<=-4) # get tweets with only very -ve scores
mean(corp.scores$score)
corp.pos[1:30,]
corp.neg[1:30,]
View(corp.pos)
corp.pos$text[1:30,]
View(corp.pos)
corp.pos$text[1:30,]
corp.pos$text[1:30]
setwd("~/Dropbox/courses/media_politics/data")
df<-read.csv("class_experiment.csv")
View(df)
names(df)
df[31]
df$y<-df[31]
lm(y ~ Treatment.Control, data=df)
View(df)
df[31]
as.vector(df[31])
df$y<-as.vector(df[31])
View(df)
as.vector(df[31,])
as.vector(df[,31])
df$y<-as.vector(df[,31])
View(df)
df$y<-df[,31]
View(df)
model<-lm(y ~ Treatment.Control, data=df)
summary(model)
View(df)
df$Treatment.Control
?read.csv
ifelse(df$Treatment.Control=="", 1,0)
ifelse(df$Treatment.Control=="", NA,df$Treatment.Control)
df$Treatment.Control<-ifelse(df$Treatment.Control=="", NA,df$Treatment.Control)
model<-lm(y ~ Treatment.Control, data=df)
summary(model)
setwd("~/Dropbox/courses/political_inquiry/data")
df<-read.csv("class_experiment.csv")
names(df)
View(df)
df$y<-df[,28]
names(df)
df$Treatment.control<-ifelse(df$Treatment.control=="", NA,df$Treatment.control)
View(df)
model<-lm(y ~ Treatment.control, data=df)
summary(model)
View(df)
model<-lm(y ~ Treatment.control + gender, data=df)
model<-lm(y ~ Treatment.control + Gender, data=df)
View(df)
names(df)
df$gender<-df[,22]
model<-lm(y ~ Treatment.control + gender, data=df)
summary(model)
model<-lm(y ~ Treatment.control + gender + Treatment.control:gender, data=df)
summary(model)
names(df)
df$edu<-df[,23]
df$edu
setwd("~/Dropbox/courses/political_inquiry/data")
df<-read.csv("class_experiment.csv")
names(df)
df$y<-df[,28]
df$gender<-df[,22]
df$edu<-df[,23]
df$Treatment.control
df$Treatment.control<-ifelse(df$Treatment.control=="", NA,df$Treatment.control)
df$Treatment.control
model<-lm(y ~ Treatment.control + gender + Treatment.control:gender, data=df)
summary(model)
setwd("~/Dropbox/courses/political_inquiry/data")
df<-read.csv("class_experiment.csv")
df$y<-df[,28]
df$gender<-df[,22]
df$edu<-df[,23]
df$x<-ifelse(df$Treatment.control==" ", NA,df$Treatment.control)
df$x
model<-lm(y ~ Treatment.control + gender, data=df)
summary(model)
apply(df, 2, function(x) gsub("^$|^ $", NA, x))
apply(df$Treatment.control, 2, function(x) gsub("^$|^ $", NA, x))
gsub("^$|^ $", NA, df$Treatment.control)
df$x<-gsub("^$|^ $", NA, df$Treatment.control)
View(df)
df$x
model<-lm(y ~ x + gender, data=df)
summary(model)
model<-lm(y ~ x, data=df)
summary(model)
setwd("~/Dropbox/courses/political_inquiry/data")
df<-read.csv("class_experiment.csv")
View(df)
setwd("~/Dropbox/courses/political_inquiry/data")
df<-read.csv("class_experiment.csv")
View(df)
names(df)
df$y<-df[,28]
df$gender<-df[,22]
df$edu<-df[,23]
df$x<-gsub("^$|^ $", NA, df$Treatment.control)
model<-lm(y ~ x, data=df)
summary(model)
df$gender<-df[,22]
df$edu<-df[,23]
model<-lm(y ~ x + gender + edu, data=df)
summary(model)
model<-lm(y ~ x + gender + edu + x:gender + x:edu, data=df)
summary(model)
model<-lm(y ~ x + gender + edu + x:gender, data=df)
summary(model)
model<-lm(y ~ x + gender + x:gender, data=df)
summary(model)
setwd("~/Dropbox/courses/media_politics/data")
df<-read.csv("class_experiment.csv")
names(df)
df$y<-df[,31]
View(df)
df$Treatment.Control
df$x<-gsub("^$|^ $", NA, df$Treatment.Control)
df$x
model<-lm(y ~ x, data=df)
summary(model)
setwd("~/Dropbox/courses/media_politics/data")
df<-read.csv("class_experiment.csv")
names(df)
df$y<-df[,31]
df$x<-gsub("^$|^ $", NA, df$Treatment.Control)
model<-lm(y ~ x, data=df)
summary(model)
df$gender<-df[,23]
df$y<-df[,31]
df$gender<-df[,23]
df$age<-df[,22]
model<-lm(y ~ x + gender + age, data=df)
summary(model)
model<-lm(y ~ x + gender, data=df)
model<-lm(y ~ x, data=df)
summary(model)
require(visreg)
visreg(model, xvar="x")
visreg(model, xvar="x", ylab="Self-Reported Interest in Politics After Watching")
visreg(model, xvar="x", ylab="Self-Reported Interest in Politics After Watching", main="Experminet")
visreg(model, xvar="x", ylab="Self-Reported Interest in Politics", main="Political Interest After Receiving Information (Treatment=Vox) Compared to Celebrity")
visreg(model, xvar="x", ylab="Self-Reported Interest in Politics", main="Experiment: Treatment=Video by Vox Compared to Celebrity")
visreg(model, xvar="x", ylab="Self-Reported Interest in Politics", main="A Survey Experiment: Treatment=Vox, Control=Kardashian")
visreg(model, xvar="x", ylab="Self-Reported Interest in Politics After Watching", main="A Survey Experiment: Treatment=Vox, Control=Kardashian")
summary(model)
visreg(model, xvar="x", ylab="Self-Reported Interest in Politics After Watching",
xlab="Randomly Assigned Video Exposure",
main="A Survey Experiment: Treatment=Vox, Control=Kardashian")
visreg(model, xvar="x", ylab="Self-Reported Interest in Politics After Watching",
xlab="Randomly Assigned Video Exposure",
main="A Survey Experiment Testing the Effect of Political Information on Political Interest")
visreg(model, xvar="x", ylab="Self-Reported Interest in Politics After Watching",
xlab="Randomly Assigned Video Exposure",
main="Experiment Testing the Effect of Political Information on Political Interest")
visreg(model, xvar="x", ylab="Self-Reported Interest in Politics After Watching",
xlab="Randomly Assigned Video Exposure",
main="The Effect of Political Information on Political Interest")
visreg(model, xvar="x", ylab="Self-Reported Interest in Politics After Watching",
xlab="Randomly Assigned Video Exposure",
main="The Effect of Political Information Video on Political Interest")
visreg(model, xvar="x", ylab="Self-Reported Interest in Politics After Watching",
xlab="Randomly Assigned Video Exposure",
main="The Effect of Political Information (Video) on Political Interest")
